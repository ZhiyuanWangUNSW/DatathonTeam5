knitr::opts_chunk$set(echo = TRUE)
file_path<-"I:\\UNSW\\Datatahon_extracted_dataset.csv"
epi_data<-read.csv(file_path)
epi_data<-clean_names(epi_data)
library(dplyr)
library(janitor)
file_path<-"I:\\UNSW\\Datatahon_extracted_dataset.csv"
epi_data<-read.csv(file_path)
epi_data<-clean_names(epi_data)
variable_name <- "country"
# Calculate the frequency
table(epi_data$country)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(janitor)
file_path<-"I:\\UNSW\\Datatahon_extracted_dataset.csv"
epi_data<-read.csv(file_path)
epi_data<-clean_names(epi_data)
head(epi_data)
summary(epi_data)
variable_name <- "country"
# Calculate the frequency
table(epi_data$country)
set.seed(42)
# Define parameters
n <- 500  # Number of rows in the dataset
countries <- c("USA", "India", "China", "Brazil", "Australia")
syndromes <- c("Respiratory", "Gastrointestinal", "Neurological", "Skin", "Other")
pandemic_types <- c("Flu", "Cholera", "SARS", "Zika", "COVID", "Ebola", "Other")
set.seed(42)
# Define parameters
n <- 500  # Number of rows in the dataset
countries <- c("USA", "India", "China", "Brazil", "Australia")
syndromes <- c("Respiratory", "Gastrointestinal", "Neurological", "Skin", "Other")
pandemic_types <- c("Flu", "Cholera", "SARS", "Zika", "COVID", "Ebola", "Other")
# Generate fake dataset
fake_data <- tibble(
Country = sample(countries, n, replace = TRUE),
Date = as.Date("2024-01-01") + sample(0:364, n, replace = TRUE),  # Random dates within 2024
Case_Name = paste0("Case_", sample(LETTERS, n, replace = TRUE)),
Syndrome = sample(syndromes, n, replace = TRUE),
Death_Number = sample(0:50, n, replace = TRUE),  # Death numbers between 0 and 50
Case_Number = sample(50:1000, n, replace = TRUE),  # Case numbers between 50 and 1000
Pandemic_Type = sample(pandemic_types, n, replace = TRUE)
)
set.seed(42)
# Define parameters
n <- 500  # Number of rows in the dataset
countries <- c("USA", "India", "China", "Brazil", "Australia")
syndromes <- c("Respiratory", "Gastrointestinal", "Neurological", "Skin", "Other")
pandemic_types <- c("Flu", "Cholera", "SARS", "Zika", "COVID", "Ebola", "Other")
# Generate fake dataset
fake_data <- tibble(
Country = sample(countries, n, replace = TRUE),
Date = as.Date("2024-01-01") + sample(0:364, n, replace = TRUE),  # Random dates within 2024
Case_Name = paste0("Case_", sample(LETTERS, n, replace = TRUE)),
Syndrome = sample(syndromes, n, replace = TRUE),
Death_Number = sample(0:50, n, replace = TRUE),  # Death numbers between 0 and 50
Case_Number = sample(50:1000, n, replace = TRUE),  # Case numbers between 50 and 1000
Pandemic_Type = sample(pandemic_types, n, replace = TRUE)
)
# Preview the dataset
print(fake_data)
set.seed(42)
# Define parameters
n <- 500  # Number of rows in the dataset
countries <- c("USA", "India", "China", "Brazil", "Australia")
syndromes <- c("Respiratory", "Gastrointestinal", "Neurological", "Skin", "Other")
pandemic_types <- c("Flu", "Cholera", "SARS", "Zika", "COVID", "Ebola", "Other")
# Generate fake dataset
fake_data <- tibble(
Country = sample(countries, n, replace = TRUE),
Date = as.Date("2024-01-01") + sample(0:364, n, replace = TRUE),  # Random dates within 2024
Case_Name = paste0("Case_", sample(LETTERS, n, replace = TRUE)),
Syndrome = sample(syndromes, n, replace = TRUE),
Death_Number = sample(0:50, n, replace = TRUE),  # Death numbers between 0 and 50
Case_Number = sample(50:1000, n, replace = TRUE),  # Case numbers between 50 and 1000
Pandemic_Type = sample(pandemic_types, n, replace = TRUE)
)
# Preview the dataset
print(fake_data)
write.csv(fake_data, "fake_pandemic_data.csv", row.names = FALSE)
library(forecast)
# Aggregate case numbers by date for a univariate time series
time_series_data <- fake_data %>%
group_by(Date) %>%
summarise(Cases = sum(Case_Number)) %>%
ungroup()
# Convert to time-series object
ts_data <- ts(time_series_data$Cases, frequency = 365)
# Fit ARIMA model
arima_model <- auto.arima(ts_data)
# Forecast future cases
forecast_data <- forecast(arima_model, h = 30)
plot(forecast_data)
library(randomForest)
# Train a random forest model
rf_model <- randomForest(
Pandemic_Type ~ Country + Death_Number + Case_Number + Syndrome,
data = fake_data,
ntree = 100
)
# Convert categorical columns to factors
fake_data <- fake_data %>%
mutate(
Country = as.factor(Country),
Syndrome = as.factor(Syndrome),
Pandemic_Type = as.factor(Pandemic_Type)
)
# Encode categorical variables
encoded_data <- fake_data %>%
mutate(
Country = as.numeric(Country),
Syndrome = as.numeric(Syndrome),
Pandemic_Type = as.numeric(Pandemic_Type)
)
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(encoded_data$Pandemic_Type, p = 0.8, list = FALSE)
library(xgtboost)
library(xgboost)
library(caret)
# Convert categorical columns to factors
fake_data <- fake_data %>%
mutate(
Country = as.factor(Country),
Syndrome = as.factor(Syndrome),
Pandemic_Type = as.factor(Pandemic_Type)
)
# Encode categorical variables
encoded_data <- fake_data %>%
mutate(
Country = as.numeric(Country),
Syndrome = as.numeric(Syndrome),
Pandemic_Type = as.numeric(Pandemic_Type)
)
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(encoded_data$Pandemic_Type, p = 0.8, list = FALSE)
train_data <- encoded_data[train_index, ]
test_data <- encoded_data[-train_index, ]
# Prepare data for XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, -7]), label = train_data$Pandemic_Type - 1)
# Label encode categorical variables
fake_data <- fake_data %>%
mutate(
Country = as.numeric(factor(Country)),
Syndrome = as.numeric(factor(Syndrome)),
Pandemic_Type = as.numeric(factor(Pandemic_Type))
)
library(xgboost)
library(caret)
# Convert categorical columns to factors
fake_data <- fake_data %>%
mutate(
Country = as.factor(Country),
Syndrome = as.factor(Syndrome),
Pandemic_Type = as.factor(Pandemic_Type)
)
# Encode categorical variables
encoded_data <- fake_data %>%
mutate(
Country = as.numeric(Country),
Syndrome = as.numeric(Syndrome),
Pandemic_Type = as.numeric(Pandemic_Type)
)
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(encoded_data$Pandemic_Type, p = 0.8, list = FALSE)
train_data <- encoded_data[train_index, ]
test_data <- encoded_data[-train_index, ]
# Prepare data for XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, -7]), label = train_data$Pandemic_Type - 1)
# Label encode categorical variables
fake_data <- fake_data %>%
mutate(
Country = as.numeric(factor(Country)),
Syndrome = as.numeric(factor(Syndrome)),
Pandemic_Type = as.numeric(factor(Pandemic_Type))
)
summary(fake_data)
# Label encode categorical variables
fake_data <- fake_data %>%
mutate(
Country = as.numeric(factor(Country)),
Syndrome = as.numeric(factor(Syndrome)),
Pandemic_Type = as.numeric(factor(Pandemic_Type),
Case_Name = as.numeric(factor(Case_Name)                          )
)
summary(fake_data)
# Label encode categorical variables
fake_data <- fake_data %>%
mutate(
Country = as.numeric(factor(Country)),
Syndrome = as.numeric(factor(Syndrome)),
Pandemic_Type = as.numeric(factor(Pandemic_Type),
Case_Name = as.numeric(factor(Case_Name)
)
summary(fake_data)
# Label encode categorical variables
fake_data <- fake_data %>%
mutate(
Country = as.numeric(factor(Country)),
Syndrome = as.numeric(factor(Syndrome)),
Pandemic_Type = as.numeric(factor(Pandemic_Type)),
Case_Name = as.numeric(factor(Case_Name)))
summary(fake_data)
library(xgboost)
library(caret)
# Convert categorical columns to factors
fake_data <- fake_data %>%
mutate(
Country = as.factor(Country),
Syndrome = as.factor(Syndrome),
Pandemic_Type = as.factor(Pandemic_Type)
)
# Encode categorical variables
encoded_data <- fake_data %>%
mutate(
Country = as.numeric(Country),
Syndrome = as.numeric(Syndrome),
Pandemic_Type = as.numeric(Pandemic_Type)
)
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(encoded_data$Pandemic_Type, p = 0.8, list = FALSE)
train_data <- encoded_data[train_index, ]
test_data <- encoded_data[-train_index, ]
# Prepare data for XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, -7]), label = train_data$Pandemic_Type - 1)
library(xgboost)
library(caret)
# Convert categorical columns to factors
fake_data <- fake_data %>%
mutate(
Country = as.factor(Country),
Syndrome = as.factor(Syndrome),
Pandemic_Type = as.factor(Pandemic_Type)
)
# Encode categorical variables
encoded_data <- fake_data %>%
mutate(
Country = as.numeric(Country),
Syndrome = as.numeric(Syndrome),
Pandemic_Type = as.numeric(Pandemic_Type)
)
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(encoded_data$Pandemic_Type, p = 0.8, list = FALSE)
train_data <- encoded_data[train_index, ]
test_data <- encoded_data[-train_index, ]
# Prepare data for XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, -7]), label = train_data$Pandemic_Type - 1)
# Label encode categorical variables
fake_data <- fake_data %>%
mutate(
Country = as.numeric(factor(Country)),
Syndrome = as.numeric(factor(Syndrome)),
Pandemic_Type = as.numeric(factor(Pandemic_Type)),
Case_Name = as.numeric(factor(Case_Name)))
summary(fake_data)
library(xgboost)
library(caret)
# Convert categorical columns to factors
fake_data <- fake_data %>%
mutate(
Country = as.factor(Country),
Syndrome = as.factor(Syndrome),
Pandemic_Type = as.factor(Pandemic_Type)
)
# Encode categorical variables
encoded_data <- fake_data %>%
mutate(
Country = as.numeric(Country),
Syndrome = as.numeric(Syndrome),
Pandemic_Type = as.numeric(Pandemic_Type)
)
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(encoded_data$Pandemic_Type, p = 0.8, list = FALSE)
train_data <- encoded_data[train_index, ]
test_data <- encoded_data[-train_index, ]
library(xgboost)
library(caret)
# Convert categorical columns to factors
fake_data <- fake_data %>%
mutate(
Country = as.factor(Country),
Syndrome = as.factor(Syndrome),
Pandemic_Type = as.factor(Pandemic_Type)
)
# Encode categorical variables
encoded_data <- fake_data %>%
mutate(
Country = as.numeric(Country),
Syndrome = as.numeric(Syndrome),
Pandemic_Type = as.numeric(Pandemic_Type)
)
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(encoded_data$Pandemic_Type, p = 0.8, list = FALSE)
train_data <- encoded_data[train_index, ]
test_data <- encoded_data[-train_index, ]
summary(train_data)
# Prepare data for XGBoost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, -7]), label = train_data$Pandemic_Type - 1)
# Set seed for reproducibility
set.seed(123)
# Define parameters
n <- 500  # Number of records
countries <- c("USA", "India", "China", "Brazil", "Australia")
cities <- list(
USA = c("New York", "Los Angeles", "Chicago"),
India = c("Mumbai", "Delhi", "Bangalore"),
China = c("Beijing", "Shanghai", "Guangzhou"),
Brazil = c("Sao Paulo", "Rio de Janeiro", "Brasilia"),
Australia = c("Sydney", "Melbourne", "Brisbane")
)
coordinates <- list(
USA = list(c(40.7128, -74.0060), c(34.0522, -118.2437), c(41.8781, -87.6298)),
India = list(c(19.0760, 72.8777), c(28.6139, 77.2090), c(12.9716, 77.5946)),
China = list(c(39.9042, 116.4074), c(31.2304, 121.4737), c(23.1291, 113.2644)),
Brazil = list(c(-23.5505, -46.6333), c(-22.9068, -43.1729), c(-15.8267, -47.9218)),
Australia = list(c(-33.8688, 151.2093), c(-37.8136, 144.9631), c(-27.4698, 153.0251))
)
syndromes <- c("Respiratory", "Gastrointestinal", "Neurological", "Skin", "Other")
pandemics <- c("Flu", "Cholera", "SARS", "Zika", "COVID", "Ebola", "Other")
# Generate base dataset
complex_data <- tibble(
Record_ID = 1:n,
Country = sample(countries, n, replace = TRUE),
Date = as.Date("2024-01-01") + sample(0:364, n, replace = TRUE),
Pandemic_Type = sample(pandemics, n, replace = TRUE),
Death_Number = sample(0:50, n, replace = TRUE),
Case_Number = sample(50:1000, n, replace = TRUE)
)
# Assign cities and coordinates based on country
complex_data <- complex_data %>%
rowwise() %>%
mutate(
City = sample(cities[[Country]], 1),
Coordinates = list(sample(coordinates[[Country]], 1))
) %>%
ungroup()
# Extract latitude and longitude from coordinates
complex_data <- complex_data %>%
mutate(
Latitude = sapply(Coordinates, function(x) x[[1]][1]),
Longitude = sapply(Coordinates, function(x) x[[1]][2])
) %>%
select(-Coordinates)  # Drop nested list column
# Assign multiple syndromes and create binary columns
complex_data <- complex_data %>%
rowwise() %>%
mutate(
Syndromes = list(sample(syndromes, sample(1:3, 1), replace = FALSE))  # Assign 1-3 random syndromes
) %>%
ungroup() %>%
mutate(across(Syndromes, ~ toString(.))) %>%
separate_rows(Syndromes, sep = ", ") %>%
mutate(value = 1) %>%
pivot_wider(names_from = Syndromes, values_from = value, values_fill = 0)
library(dplyr)
library(janitor)
library(tidyr)
# Set seed for reproducibility
set.seed(123)
# Define parameters
n <- 500  # Number of records
countries <- c("USA", "India", "China", "Brazil", "Australia")
cities <- list(
USA = c("New York", "Los Angeles", "Chicago"),
India = c("Mumbai", "Delhi", "Bangalore"),
China = c("Beijing", "Shanghai", "Guangzhou"),
Brazil = c("Sao Paulo", "Rio de Janeiro", "Brasilia"),
Australia = c("Sydney", "Melbourne", "Brisbane")
)
coordinates <- list(
USA = list(c(40.7128, -74.0060), c(34.0522, -118.2437), c(41.8781, -87.6298)),
India = list(c(19.0760, 72.8777), c(28.6139, 77.2090), c(12.9716, 77.5946)),
China = list(c(39.9042, 116.4074), c(31.2304, 121.4737), c(23.1291, 113.2644)),
Brazil = list(c(-23.5505, -46.6333), c(-22.9068, -43.1729), c(-15.8267, -47.9218)),
Australia = list(c(-33.8688, 151.2093), c(-37.8136, 144.9631), c(-27.4698, 153.0251))
)
syndromes <- c("Respiratory", "Gastrointestinal", "Neurological", "Skin", "Other")
pandemics <- c("Flu", "Cholera", "SARS", "Zika", "COVID", "Ebola", "Other")
# Generate base dataset
complex_data <- tibble(
Record_ID = 1:n,
Country = sample(countries, n, replace = TRUE),
Date = as.Date("2024-01-01") + sample(0:364, n, replace = TRUE),
Pandemic_Type = sample(pandemics, n, replace = TRUE),
Death_Number = sample(0:50, n, replace = TRUE),
Case_Number = sample(50:1000, n, replace = TRUE)
)
# Assign cities and coordinates based on country
complex_data <- complex_data %>%
rowwise() %>%
mutate(
City = sample(cities[[Country]], 1),
Coordinates = list(sample(coordinates[[Country]], 1))
) %>%
ungroup()
# Extract latitude and longitude from coordinates
complex_data <- complex_data %>%
mutate(
Latitude = sapply(Coordinates, function(x) x[[1]][1]),
Longitude = sapply(Coordinates, function(x) x[[1]][2])
) %>%
select(-Coordinates)  # Drop nested list column
# Assign multiple syndromes and create binary columns
complex_data <- complex_data %>%
rowwise() %>%
mutate(
Syndromes = list(sample(syndromes, sample(1:3, 1), replace = FALSE))  # Assign 1-3 random syndromes
) %>%
ungroup() %>%
mutate(across(Syndromes, ~ toString(.))) %>%
separate_rows(Syndromes, sep = ", ") %>%
mutate(value = 1) %>%
pivot_wider(names_from = Syndromes, values_from = value, values_fill = 0)
str(complex_data)
# Assign multiple syndromes and create binary columns
complex_data <- complex_data %>%
rowwise() %>%
mutate(
Syndromes = list(sample(syndromes, sample(1:3, 1), replace = FALSE))  # Assign 1-3 random syndromes
) %>%
ungroup() %>%
mutate(across(Syndromes, ~ toString(.))) %>%
separate_rows(Syndromes, sep = ", ") %>%
mutate(value = 1) %>%
pivot_wider(names_from = Syndromes, values_from = value, values_fill = 0)
str(complex_data)
# Set up syndromes
syndromes <- c("Respiratory", "Gastrointestinal", "Neurological", "Skin", "Other")
# Add a random list of syndromes for each record
complex_data <- complex_data %>%
rowwise() %>%
mutate(
Syndromes = list(sample(syndromes, size = sample(1:3, 1), replace = FALSE))  # 1â€“3 random syndromes
) %>%
ungroup()
# Unnest syndromes and prepare for pivoting
complex_data <- complex_data %>%
unnest_longer(Syndromes) %>%
mutate(value = 1)  # Add a binary indicator for each syndrome
# Pivot wider to create binary columns for each syndrome
complex_data <- complex_data %>%
pivot_wider(
names_from = Syndromes,
values_from = value,
values_fill = list(value = 0)  # Fill missing syndromes with 0
)
print(complex_data)
write.csv(complex_data, "fake_pandemic_data.csv", row.names = FALSE)
# Add a new Phase column with random values from 1 to 6
complex_data <- complex_data %>%
mutate(
Phase = sample(paste("Phase", 1:6), n(), replace = TRUE)
)
# Add a new Phase column with random values from 1 to 6
complex_data <- complex_data %>%
mutate(
Phase = sample(paste("Phase", 1:6), n(), replace = TRUE)
)
# View the updated dataset
print(head(complex_data))
# Create a data frame with city coordinates
city_coordinates <- tibble::tibble(
City = c("New York", "Los Angeles", "Chicago", "Mumbai", "Delhi", "Bangalore",
"Beijing", "Shanghai", "Guangzhou", "Sao Paulo", "Rio de Janeiro", "Brasilia",
"Sydney", "Melbourne", "Brisbane"),
Latitude = c(40.7128, 34.0522, 41.8781, 19.0760, 28.6139, 12.9716,
39.9042, 31.2304, 23.1291, -23.5505, -22.9068, -15.8267,
-33.8688, -37.8136, -27.4698),
Longitude = c(-74.0060, -118.2437, -87.6298, 72.8777, 77.2090, 77.5946,
116.4074, 121.4737, 113.2644, -46.6333, -43.1729, -47.9218,
151.2093, 144.9631, 153.0251)
)
# Update the complex_data dataset with real coordinates
complex_data <- complex_data %>%
left_join(city_coordinates, by = "City") %>%
select(-Latitude.x, -Longitude.x) %>%  # Remove old coordinate columns
rename(
Latitude = Latitude.y,
Longitude = Longitude.y
)
# View the updated dataset
print(head(complex_data))
# Create a data frame for disease transmission mapping
disease_transmission <- tibble::tibble(
Pandemic_Type = c("Flu", "Cholera", "SARS", "Zika", "COVID", "Ebola", "Other"),
Transmission_Type = c("person-to-person", "person-to-person", "animal-to-person",
"animal-to-person", "person-to-person", "animal-to-person",
"unknown")
)
# Add transmission type to the dataset
complex_data <- complex_data %>%
left_join(disease_transmission, by = "Pandemic_Type")
# View the updated dataset
print(head(complex_data))
write.csv(complex_data, "fake_pandemic_data.csv", row.names = FALSE)
